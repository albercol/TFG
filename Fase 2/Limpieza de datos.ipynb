{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limpieza de datos del archivo de contaminacion\n",
    "Eliminacion de columnas 'PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO', 'source_file'.\n",
    "\n",
    "Mirar si hay fechas repetidas. (NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "path = os.getcwd()\n",
    "os.makedirs(path + \"/DatosLimpios\", exist_ok=True)\n",
    "fichero = \"https://raw.githubusercontent.com/albercol/TFG/main/Fase%201.3/PlazaEliptica/ContaminacionPlazaEliptica.csv\"\n",
    "df =  pd.read_csv(fichero,encoding=\"UTF-8\")\n",
    "df = df.drop(['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO', 'source_file', 'V01','V02', 'V03','V04',\n",
    "             'V05','V06','V07','V08', 'V09','V10','V11', 'V12', 'V13','V14', 'V15','V16','V17','V18','V19','V20',\n",
    "             'V21','V22','V23', 'V24'], axis=1)\n",
    "\n",
    "df.sort_values(['ANO','MES','DIA', 'MAGNITUD'], inplace=True)\n",
    "\n",
    "#convertimos las horas en una unica columna.\n",
    "df1 = pd.melt(df, id_vars =['DIA','MES','ANO','MAGNITUD'], var_name= \"HORA\")\n",
    "#Ordenamos por magnitud.\n",
    "df1.sort_values(['ANO','MES','DIA', 'MAGNITUD'], inplace=True)\n",
    "#Convertimos las magnitudes en distintas columnas.\n",
    "df2 = pd.pivot_table(df1, index=['DIA','MES','ANO','HORA'], columns=[\"MAGNITUD\"],values='value').reset_index()\n",
    "#Renombramos las columnas.\n",
    "df2.set_axis(['DIA', 'MES', 'ANO', 'HORA', 'CO' , 'NO', 'NO2', 'PM2.5', 'PM10', 'NOx', 'O3'], axis='columns', inplace=True)\n",
    "\n",
    "#Transformamos el formato hora a numeros enteros\n",
    "df2['HORA'] = df2['HORA'].str.extract('(\\d+)', expand=False)\n",
    "\n",
    "#convertimos las la hora y los cintaminantes posibles a enteros\n",
    "magnitudes = ['HORA','NO','NO2','NOx']\n",
    "for c in magnitudes:\n",
    "    df2[c] = df2[c].astype(int) \n",
    "\n",
    "#Ordenamos por año, mes y dia\n",
    "df2.sort_values(['ANO', 'MES', 'DIA', 'HORA'], inplace=True)\n",
    "\n",
    "#Guardamos en .CSV\n",
    "df2.to_csv(path+\"/DatosLimpios/\"+\"Contaminacion.csv\", header=True, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de datos del archivo de Meteorología.\n",
    "Eliminacion de columnas ('PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO', 'source_file') (SI)\n",
    "\n",
    "Mirar si hay fechas repetidas. (NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "path = os.getcwd()\n",
    "os.makedirs(path + \"/DatosLimpios\", exist_ok=True)\n",
    "fichero = \"https://raw.githubusercontent.com/albercol/TFG/main/Fase%201.3/PlazaEliptica/MeteorologiaPlazaEliptica.csv\"\n",
    "df =  pd.read_csv(fichero,encoding=\"UTF-8\")\n",
    "df = df.drop(['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO', 'source_file', 'V01','V02', 'V03','V04',\n",
    "             'V05','V06','V07','V08', 'V09','V10','V11', 'V12', 'V13','V14', 'V15','V16','V17','V18','V19','V20',\n",
    "             'V21','V22','V23', 'V24'], axis=1)\n",
    "\n",
    "df.sort_values(['ANO','MES','DIA', 'MAGNITUD'], inplace=True)\n",
    "\n",
    "#convertimos las horas en una unica columna.\n",
    "df1 = pd.melt(df, id_vars =['DIA','MES','ANO','MAGNITUD'], var_name= \"HORA\")\n",
    "#Ordenamos por magnitud.\n",
    "df1.sort_values(['ANO','MES','DIA', 'MAGNITUD'], inplace=True)\n",
    "#Convertimos las magnitudes en distintas columnas.\n",
    "df2 = pd.pivot_table(df1, index=['DIA','MES','ANO','HORA'], columns=[\"MAGNITUD\"] ,values='value').reset_index()\n",
    "df2.set_axis(['DIA', 'MES', 'ANO', 'HORA', 'VELOCIDAD VIENTO' , 'DIR. VIENTO', 'TEMPERATURA', 'HUMEDAD RELATIVA', 'PRESION BARIOMETRICA', 'PRECIPITACIONES'], axis='columns', inplace=True)\n",
    "#Transformamos el formato hora a numeros enteros\n",
    "df2['HORA'] = df2['HORA'].str.extract('(\\d+)', expand=False)\n",
    "\n",
    "magnitudes = ['HORA', 'HUMEDAD RELATIVA', 'PRESION BARIOMETRICA']\n",
    "for c in magnitudes:\n",
    "    df2[c] = df2[c].astype(int) \n",
    "    \n",
    "#Ordenamos por año, mes y dia\n",
    "df2.sort_values(['ANO', 'MES', 'DIA', 'HORA'], inplace=True)\n",
    "\n",
    "#Guardamos en .CSV\n",
    "df2.to_csv(path+\"/DatosLimpios/\"+\"Meteorologia.csv\", header=True, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de datos del archivo de trafico.\n",
    "Separar la fecha en tres columnas.(SI)\n",
    "\n",
    "Mirar si hay fechas repetidas. (NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alberto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Alberto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Alberto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Alberto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Alberto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Alberto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "path = os.getcwd()\n",
    "os.makedirs(path + \"/DatosLimpios\", exist_ok=True)\n",
    "\n",
    "#Separamos la fecha en tres columnas y eliminamos la columna 'FDIA'\n",
    "fichero = \"https://raw.githubusercontent.com/albercol/TFG/main/Fase%201.3/PlazaEliptica/TraficoPlazaEliptica.csv\"\n",
    "df =  pd.read_csv(fichero,encoding=\"UTF-8\")\n",
    "df['FDIA'] = pd.to_datetime(df['FDIA'], dayfirst=True)\n",
    "df.insert(2, 'DIA', df.mean(1))\n",
    "df.insert(2, 'MES', df.mean(1))\n",
    "df.insert(2, 'ANO', df.mean(1))\n",
    "df['DIA']=df['FDIA'].dt.day\n",
    "df['MES']=df['FDIA'].dt.month\n",
    "df['ANO']=df['FDIA'].dt.year\n",
    "df = df.drop(['FDIA'], axis=1)\n",
    "\n",
    "freq = df.groupby(['ANO', 'MES', 'DIA']).size()\n",
    "\n",
    "#Ordenamos por año, mes dia y estacion.\n",
    "df.sort_values(['ANO','MES','DIA', 'FEST'], inplace=True)\n",
    "df \n",
    "#convertimos las horas en una unica columna.\n",
    "df1 = pd.melt(df, id_vars =['DIA','MES','ANO','FEST'], var_name= \"HORA\")\n",
    "#Ordenamos por magnitud.\n",
    "df1.sort_values(['ANO','MES','DIA', 'FEST'], inplace=True)\n",
    "#Convertimos las magnitudes en distintas columnas.\n",
    "df2 = pd.pivot_table(df1, index=['DIA','MES','ANO','HORA'], columns=[\"FEST\"] ,values='value').reset_index()\n",
    "#Transformamos el formato hora a numeros enteros\n",
    "df2['HORA'] = df2['HORA'].str.extract('(\\d+)', expand=False)\n",
    "\n",
    "magnitudes = ['HORA', 'ES10', 'ES53', 'ES54']\n",
    "for c in magnitudes:\n",
    "    df2[c] = df2[c].astype(int) \n",
    "\n",
    "#Ordenamos por año mes y dia\n",
    "df2.sort_values(['ANO', 'MES', 'DIA', 'HORA'], inplace=True)\n",
    "#Guardamos en .CSV\n",
    "df2.to_csv(path+\"/DatosLimpios/\"+\"Trafico.csv\", header=True, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
